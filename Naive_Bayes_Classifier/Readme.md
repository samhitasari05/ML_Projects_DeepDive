# ğŸ“¨ Filtering by Probability: A Naive Bayes Classification Project

This project explores **Naive Bayes Classification**, a probabilistic machine learning algorithm based on Bayes' Theorem. Itâ€™s known for its simplicity, speed, and surprising performance â€” especially on text and categorical data.

ğŸ§ª Completed as part of AIT 636 (Machine Learning) at George Mason University, this project implements a Gaussian Naive Bayes classifier to predict categorical outcomes from structured numerical features.

---

## ğŸ§  What is Naive Bayes?

Naive Bayes uses conditional probability to predict the class of a given data point. It assumes that the features are **independent**, which simplifies computation and makes it extremely fast.

Itâ€™s commonly used for:
- Spam filtering
- Text classification
- Sentiment analysis
- Medical diagnosis

---

## ğŸš€ What This Project Covers

- Implementing a **Gaussian Naive Bayes** model using `scikit-learn`
- Splitting data into training and test sets
- Predicting class labels on unseen data
- Evaluating model using:
  - Accuracy
  - Confusion matrix
  - Precision, recall, and F1 score
- Interpreting results in a structured report

---

## ğŸ“Š Results Summary

> âœ… Model achieved strong classification performance on the target dataset  
> âœ… Showed balanced precision and recall  
> âœ… Confirmed assumptions about feature independence and normality for Gaussian NB

---

## ğŸ—‚ï¸ Files Included

- `Naive_Bayes.py` â€” Main Naive Bayes implementation  
- `Naive_Bayes_Results.pdf` â€” Report with metrics and evaluation  

---

## ğŸ“š Technologies & Libraries

```bash
scikit-learn
pandas
numpy
matplotlib

